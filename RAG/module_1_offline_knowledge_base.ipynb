{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一模块：离线知识库构建\n",
    "\n",
    "本 Notebook 实现酒店评论 RAG 系统的离线知识库构建流程：\n",
    "\n",
    "1. **评论质量评估** - 使用 LLM 对评论进行质量评分\n",
    "2. **评论分类** - 将评论归类到 5 大类中的 14 小类\n",
    "3. **类别摘要生成** - 为每个小类生成摘要\n",
    "4. **反向 Query 生成** - 为每条评论生成 1-3 个问题\n",
    "5. **向量数据库构建** - 构建 3 个向量数据库（评论库、反向 Query 库、摘要库）\n",
    "6. **倒排索引构建** - 基于 BM25 算法构建文本检索索引\n",
    "\n",
    "**前置条件**：\n",
    "- 清洗后的数据文件：`data/processed/hotel_comments_cleaned.csv`\n",
    "- 配置文件：`config/categories.json`, `config/stopwords_chinese.txt`\n",
    "- 环境变量：`DASHSCOPE_API_KEY`, `DASHVECTOR_API_KEY`, `DASHVECTOR_HOTEL_ENDPOINT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境配置\n",
    "\n",
    "`pip install dashscope dashvector chromadb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import nltk\n",
    "import jieba\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 下载停用词\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# API 客户端\n",
    "from dashscope import Generation, TextEmbedding\n",
    "import dashvector\n",
    "from dashvector import Doc\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境变量检测成功:\n",
      "- DASHSCOPE_API_KEY: sk-5540c66...f37a\n",
      "- DASHVECTOR_API_KEY: sk-W6G93uB...7EDE\n",
      "- DASHVECTOR_HOTEL_ENDPOINT: vrs-cn-e4k....com\n"
     ]
    }
   ],
   "source": [
    "# 检查环境变量\n",
    "required_env = {\n",
    "    \"DASHSCOPE_API_KEY\": os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    \"DASHVECTOR_API_KEY\": os.getenv(\"DASHVECTOR_API_KEY\"),\n",
    "    \"DASHVECTOR_HOTEL_ENDPOINT\": os.getenv(\"DASHVECTOR_HOTEL_ENDPOINT\"),\n",
    "}\n",
    "\n",
    "missing = [k for k, v in required_env.items() if not v]\n",
    "if missing:\n",
    "    raise EnvironmentError(f\"缺少环境变量: {', '.join(missing)}\")\n",
    "\n",
    "print(\"环境变量检测成功:\")\n",
    "for key, value in required_env.items():\n",
    "    print(f\"- {key}: {value[:10]}...{value[-4:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目根目录: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\n",
      "LLM 模型: deepseek-v3.2\n",
      "Emb 模型: text-embedding-v4（维度: 1024）\n"
     ]
    }
   ],
   "source": [
    "# 项目路径配置\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
    "\n",
    "# 模型配置\n",
    "LLM_MODEL = \"deepseek-v3.2\"\n",
    "EMBEDDING_MODEL = \"text-embedding-v4\"\n",
    "EMBEDDING_DIMENSION = 1024\n",
    "\n",
    "print(f\"项目根目录: {PROJECT_ROOT}\")\n",
    "print(f\"LLM 模型: {LLM_MODEL}\")\n",
    "print(f\"Emb 模型: {EMBEDDING_MODEL}（维度: {EMBEDDING_DIMENSION}）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 客户端\n",
    "class LLMClient:\n",
    "    \"\"\"Qwen 客户端封装\"\"\"\n",
    "    def __init__(self, api_key: str, model: str = \"qwen-plus\", json: bool = False):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.json = json\n",
    "    \n",
    "    def generate(self, prompt: str, temperature: float = 0.7) -> str:\n",
    "        \"\"\"生成文本\"\"\"\n",
    "        response = Generation.call(\n",
    "            api_key=self.api_key,\n",
    "            model=self.model,\n",
    "            prompt=prompt,\n",
    "            temperature=temperature,\n",
    "            result_format=\"message\",\n",
    "            response_format={\"type\": \"json_object\"} if self.json else None\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.output.choices[0].message.content.strip()\n",
    "        else:\n",
    "            raise RuntimeError(f\"LLM 调用失败: {response.message}\")\n",
    "\n",
    "\n",
    "# Embedding 客户端\n",
    "class EmbeddingClient:\n",
    "    \"\"\"文本嵌入客户端封装\"\"\"\n",
    "    def __init__(self, api_key: str, model: str = \"text-embedding-v4\", dimension: int = 1024):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.dimension = dimension\n",
    "    \n",
    "    def embed_batch(self, texts: list[str]) -> list[list[float]]:\n",
    "        \"\"\"批量生成 embedding\"\"\"\n",
    "        response = TextEmbedding.call(\n",
    "            api_key=self.api_key,\n",
    "            model=self.model,\n",
    "            input=texts,\n",
    "            dimension=self.dimension\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return [item['embedding'] for item in response.output['embeddings']]\n",
    "        else:\n",
    "            raise RuntimeError(f\"Embedding 调用失败: {response.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB Path: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "# 初始化 LLM & Embedding 客户端\n",
    "llm_client = LLMClient(api_key=required_env[\"DASHSCOPE_API_KEY\"], model=LLM_MODEL, json=True)\n",
    "embedding_client = EmbeddingClient(\n",
    "    api_key=required_env[\"DASHSCOPE_API_KEY\"],\n",
    "    model=EMBEDDING_MODEL,\n",
    "    dimension=EMBEDDING_DIMENSION\n",
    ")\n",
    "BATCH_SIZE = 10  # text-embedding-v4 模型支持的最大 batch size\n",
    "\n",
    "# 初始化向量数据库客户端\n",
    "dashvector_client = dashvector.Client(\n",
    "    api_key=required_env[\"DASHVECTOR_API_KEY\"],\n",
    "    endpoint=required_env[\"DASHVECTOR_HOTEL_ENDPOINT\"]\n",
    ")\n",
    "\n",
    "chroma_db_path = DATA_DIR / \"chroma_db\"\n",
    "chroma_db_path.mkdir(parents=True, exist_ok=True)\n",
    "chroma_client = chromadb.PersistentClient(path=str(chroma_db_path))\n",
    "print(f\"ChromaDB Path: {chroma_db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原数据共 2542 条评论\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>images</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>room_type</th>\n",
       "      <th>fuzzy_room_type</th>\n",
       "      <th>travel_type</th>\n",
       "      <th>comment_len</th>\n",
       "      <th>log_comment_len</th>\n",
       "      <th>useful_count</th>\n",
       "      <th>log_useful_count</th>\n",
       "      <th>review_count</th>\n",
       "      <th>log_review_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68027895e3c98b0941765706</th>\n",
       "      <td>房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...</td>\n",
       "      <td>[ \"https://dimg04.c-ctrip.com/images/0230y1200...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>红棉大床套房</td>\n",
       "      <td>套房</td>\n",
       "      <td>家庭亲子</td>\n",
       "      <td>320</td>\n",
       "      <td>5.771441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    comment  \\\n",
       "_id                                                                           \n",
       "68027895e3c98b0941765706  房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...   \n",
       "\n",
       "                                                                     images  \\\n",
       "_id                                                                           \n",
       "68027895e3c98b0941765706  [ \"https://dimg04.c-ctrip.com/images/0230y1200...   \n",
       "\n",
       "                          score publish_date room_type fuzzy_room_type  \\\n",
       "_id                                                                      \n",
       "68027895e3c98b0941765706    5.0   2025-04-05    红棉大床套房              套房   \n",
       "\n",
       "                         travel_type  comment_len  log_comment_len  \\\n",
       "_id                                                                  \n",
       "68027895e3c98b0941765706        家庭亲子          320         5.771441   \n",
       "\n",
       "                          useful_count  log_useful_count  review_count  \\\n",
       "_id                                                                      \n",
       "68027895e3c98b0941765706             0               0.0             7   \n",
       "\n",
       "                          log_review_count  \n",
       "_id                                         \n",
       "68027895e3c98b0941765706          2.079442  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "raw_data_file = PROCESSED_DATA_DIR / \"hotel_comments_cleaned.csv\"\n",
    "df_raw = pd.read_csv(raw_data_file, index_col=0)\n",
    "\n",
    "print(f\"原数据共 {len(df_raw)} 条评论\")\n",
    "df_raw.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1：评论质量评估\n",
    "\n",
    "对每条评论进行质量评分（0-10分），过滤低质量评论（≤4分）\n",
    "- 可以与步骤二、四合并，每条评论只调用一次 LLM\n",
    "- 可以开启多线程并行调用 API 以节省时间\n",
    "- 可以设置 checkpoint 保存中间结果，避免因网络波动导致的 API 调用中断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 质量评估 Prompt\n",
    "QUALITY_ASSESSMENT_PROMPT = \"\"\"\n",
    "你是一位专业的评论质量评估专家,请对以下酒店评论进行质量打分(0-10分)\n",
    "\n",
    "评分标准:\n",
    "- 9-10分: 信息丰富,具体详细,有明确的观点和充分的细节支持\n",
    "- 7-8分: 有一定信息量,提供了较为具体的内容\n",
    "- 5-6分: 信息量中等,有些笼统但仍有参考价值\n",
    "- 3-4分: 信息量较少,过于简短或模糊\n",
    "- 0-2分: 几乎没有实质内容,如只有\"好\"、\"不错\"等\n",
    "\n",
    "评论内容: {comment}\n",
    "\n",
    "直接返回JSON格式:\n",
    "{{\n",
    "    \"quality_score\": 分数(0-10的整数)\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def assess_quality(comment: str, index: int) -> int:\n",
    "    \"\"\"评估单条评论质量\"\"\"\n",
    "    prompt = QUALITY_ASSESSMENT_PROMPT.format(comment=comment)\n",
    "    \n",
    "    for i in range(3):\n",
    "        try:\n",
    "            response = llm_client.generate(prompt, temperature=0.3)\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            data = json.loads(response)\n",
    "            return int(data['quality_score'])\n",
    "        except Exception as e:\n",
    "            print(f\"索引为 {index} 的评论第 {i+1} 次尝试失败: {e}\")\n",
    "            if i < 2:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "    print(f\"索引为 {index} 的评论评估失败，已返回 -1\")\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745ac8cd15f145cc8edb351aeacda07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "质量评估:   0%|          | 0/2542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均质量分: 6.87\n",
      "质量分布:\n",
      "quality_score\n",
      "0       4\n",
      "1      15\n",
      "2      45\n",
      "3     110\n",
      "4     197\n",
      "5     181\n",
      "6     306\n",
      "7     542\n",
      "8     589\n",
      "9     537\n",
      "10     16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 批量质量评估\n",
    "quality_results = []\n",
    "\n",
    "for index, row in tqdm(df_raw.iterrows(), total=len(df_raw), desc=\"质量评估\"):\n",
    "    score = assess_quality(row['comment'], index)\n",
    "    quality_results.append(score)\n",
    "    time.sleep(0.1)  # API 限流保护\n",
    "\n",
    "df_raw['quality_score'] = quality_results\n",
    "\n",
    "print(f\"平均质量分: {df_raw['quality_score'].mean():.2f}\")\n",
    "print(f\"质量分布:\\n{df_raw['quality_score'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原有评论数: 2542\n",
      "保留评论数: 2171 (quality_score >= 5)\n",
      "过滤评论数: 371\n",
      "保留比例: 85.4%\n"
     ]
    }
   ],
   "source": [
    "# 查看低质量评论数量\n",
    "num_raw = len(df_raw)\n",
    "num_filtered = len(df_raw[df_raw['quality_score'] >= 5])\n",
    "\n",
    "print(f\"原有评论数: {num_raw}\")\n",
    "print(f\"保留评论数: {num_filtered} (quality_score >= 5)\")\n",
    "print(f\"过滤评论数: {num_raw - num_filtered}\")\n",
    "print(f\"保留比例: {num_filtered / num_raw * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2：评论分类\n",
    "\n",
    "将每条评论归类到 1-3 个小类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'性价比', '交通便利性', '安静程度', '前台服务', '退房/入住效率', '周边配套', '景观/朝向', '房间设施', '价格合理性', '卫生状况', '公共设施', '餐饮设施', '整体满意度', '客房服务'}\n",
      "\n",
      "【设施类】\n",
      "  - **房间设施**, 例如: 床、卫浴、空调、wifi、电视、冰箱、热水等\n",
      "  - **公共设施**, 例如: 泳池、健身房、停车场、会议室、商务中心等\n",
      "  - **餐饮设施**, 例如: 早餐、餐厅、酒吧、客房送餐等\n",
      "【服务类】\n",
      "  - **前台服务**, 例如: 入住、退房、礼宾、咨询、态度等\n",
      "  - **客房服务**, 例如: 打扫、整理、送物、维修等\n",
      "  - **退房/入住效率**, 例如: 速度、流程、等待时间等\n",
      "【位置类】\n",
      "  - **交通便利性**, 例如: 地铁、公交、机场、火车站、打车等\n",
      "  - **周边配套**, 例如: 商场、餐饮、景点、医院、银行等\n",
      "  - **景观/朝向**, 例如: 江景、园景、城景、无窗等\n",
      "【价格类】\n",
      "  - **性价比**, 例如: 值得、划算、超值、合理等\n",
      "  - **价格合理性**, 例如: 贵、便宜、优惠、折扣等\n",
      "【体验类】\n",
      "  - **整体满意度**, 例如: 满意、推荐、舒适、愉快等\n",
      "  - **安静程度**, 例如: 安静、吵闹、隔音等\n",
      "  - **卫生状况**, 例如: 干净、卫生、整洁、清洁等\n"
     ]
    }
   ],
   "source": [
    "# 加载分类体系\n",
    "with open(CONFIG_DIR / \"categories.json\", 'r', encoding='utf-8') as f:\n",
    "    categories_config = json.load(f)\n",
    "\n",
    "# 提取所需小类名称\n",
    "my_categories = set()\n",
    "for cat in categories_config['categories']:\n",
    "    for subcat in cat['subcategories']:\n",
    "        my_categories.add(subcat['name'])\n",
    "print(my_categories, end=\"\\n\\n\")\n",
    "\n",
    "# 构建分类提示词的类别字典\n",
    "def format_categories_for_prompt(config: dict) -> str:\n",
    "    \"\"\"格式化分类体系为提示词文本\"\"\"\n",
    "    lines = []\n",
    "    for cat in config['categories']:\n",
    "        lines.append(f\"【{cat['name']}】\")\n",
    "        for subcat in cat['subcategories']:\n",
    "            subcategories_str = \"、\".join(subcat['subcategories'])\n",
    "            lines.append(f\"  - **{subcat['name']}**, 例如: {subcategories_str}等\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "categories_text = format_categories_for_prompt(categories_config)\n",
    "print(categories_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类 Prompt\n",
    "CLASSIFICATION_PROMPT = \"\"\"\n",
    "你是一位专业的评论分类专家,请将以下酒店评论归类到给出的5个大类14个小类中最相关的1-3个小类\n",
    "\n",
    "可选的分类体系:\n",
    "{categories}\n",
    "\n",
    "评论内容: {comment}\n",
    "\n",
    "请分析评论内容,选择1-3个最相关的小类。若都不是则输出空列表。直接返回JSON格式:\n",
    "{{\n",
    "    \"categories\": [\"小类1\", \"小类2\", \"小类3\"]\n",
    "}}\n",
    "\n",
    "输出示例1:\n",
    "{{\n",
    "    \"categories\": [\"房间设施\", \"交通便利性\", \"安静程度\"]\n",
    "}}\n",
    "\n",
    "输出示例2:\n",
    "{{\n",
    "    \"categories\": []\n",
    "}}\n",
    "\n",
    "注意:\n",
    "1. categories数组中只能出现以上给出的小类名称(即被加粗的内容,**xxx**),不允许出现大类名称(即被框出的内容,【xxx】),不允许出现多余符号,严禁自行编造未给出的小类名称\n",
    "2. 若评论中未明确指出具体小类,如仅提到\"服务到位\",则输出与之相关的小类名称,如[\"前台服务\", \"客房服务\", \"退房/入住效率\"],严禁直接输出大类名称[\"服务类\"]\n",
    "3. 如果评论只涉及1-2个类别或涉及其他类别的内容极少,数组中就只放1-2个元素,不要强行输出3个类别,优先保证类别与评论的相关性\n",
    "4. 按相关性从高到低排序\n",
    "\"\"\"\n",
    "\n",
    "def classify_comment(comment: str, index: int) -> list:\n",
    "    \"\"\"分类单条评论\"\"\"\n",
    "    prompt = CLASSIFICATION_PROMPT.format(categories=categories_text, comment=comment)\n",
    "    \n",
    "    for i in range(3):\n",
    "        try:\n",
    "            response = llm_client.generate(prompt, temperature=0.1)\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            data = json.loads(response)\n",
    "            categories = data['categories']\n",
    "            valid_categories = [cat for cat in categories if cat in my_categories]  # 过滤出在合法集合中的类别\n",
    "            return valid_categories\n",
    "        except Exception as e:\n",
    "            print(f\"索引为 {index} 的评论第 {i+1} 次尝试失败: {e}\")\n",
    "            if i < 2:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    \n",
    "    print(f\"索引为 {index} 的评论分类失败，已返回空列表\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3659375cb4a4eedb67a9261cf3df0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "评论分类:   0%|          | 0/2542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 批量分类\n",
    "classification_results = []\n",
    "\n",
    "for index, row in tqdm(df_raw.iterrows(), total=len(df_raw), desc=\"评论分类\"):\n",
    "    result = classify_comment(row['comment'], index)\n",
    "    classification_results.append(result)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "df_raw['categories'] = classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 14 个小类有评论:\n",
      "- 整体满意度: 1855 条评论\n",
      "- 前台服务: 1352 条评论\n",
      "- 餐饮设施: 705 条评论\n",
      "- 房间设施: 619 条评论\n",
      "- 交通便利性: 465 条评论\n",
      "- 卫生状况: 403 条评论\n",
      "- 公共设施: 277 条评论\n",
      "- 客房服务: 261 条评论\n",
      "- 周边配套: 250 条评论\n",
      "- 性价比: 156 条评论\n",
      "- 安静程度: 147 条评论\n",
      "- 退房/入住效率: 105 条评论\n",
      "- 景观/朝向: 88 条评论\n",
      "- 价格合理性: 13 条评论\n"
     ]
    }
   ],
   "source": [
    "# 按小类聚合评论\n",
    "category_comments = defaultdict(list)\n",
    "\n",
    "for _, row in df_raw.iterrows():\n",
    "    for cat in row['categories']:\n",
    "        category_comments[cat].append({\n",
    "            'comment': row['comment'],\n",
    "            'quality_score': row['quality_score']\n",
    "        })\n",
    "\n",
    "print(f\"共 {len(category_comments)} 个小类有评论:\")\n",
    "for cat, comments in sorted(category_comments.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    print(f\"- {cat}: {len(comments)} 条评论\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "扩展后的评论数据已保存: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\enriched_comments.csv\n",
      "过滤后的评论数据已保存: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\filtered_comments.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>images</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>room_type</th>\n",
       "      <th>fuzzy_room_type</th>\n",
       "      <th>travel_type</th>\n",
       "      <th>comment_len</th>\n",
       "      <th>log_comment_len</th>\n",
       "      <th>useful_count</th>\n",
       "      <th>log_useful_count</th>\n",
       "      <th>review_count</th>\n",
       "      <th>log_review_count</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68027895e3c98b0941765706</th>\n",
       "      <td>房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...</td>\n",
       "      <td>[ \"https://dimg04.c-ctrip.com/images/0230y1200...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>红棉大床套房</td>\n",
       "      <td>套房</td>\n",
       "      <td>家庭亲子</td>\n",
       "      <td>320</td>\n",
       "      <td>5.771441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>9</td>\n",
       "      <td>[整体满意度, 餐饮设施, 前台服务]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    comment  \\\n",
       "_id                                                                           \n",
       "68027895e3c98b0941765706  房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...   \n",
       "\n",
       "                                                                     images  \\\n",
       "_id                                                                           \n",
       "68027895e3c98b0941765706  [ \"https://dimg04.c-ctrip.com/images/0230y1200...   \n",
       "\n",
       "                          score publish_date room_type fuzzy_room_type  \\\n",
       "_id                                                                      \n",
       "68027895e3c98b0941765706    5.0   2025-04-05    红棉大床套房              套房   \n",
       "\n",
       "                         travel_type  comment_len  log_comment_len  \\\n",
       "_id                                                                  \n",
       "68027895e3c98b0941765706        家庭亲子          320         5.771441   \n",
       "\n",
       "                          useful_count  log_useful_count  review_count  \\\n",
       "_id                                                                      \n",
       "68027895e3c98b0941765706             0               0.0             7   \n",
       "\n",
       "                          log_review_count  quality_score           categories  \n",
       "_id                                                                             \n",
       "68027895e3c98b0941765706          2.079442              9  [整体满意度, 餐饮设施, 前台服务]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存扩展后的评论数据\n",
    "enriched_file = PROCESSED_DATA_DIR / \"enriched_comments.csv\"\n",
    "df_raw.to_csv(enriched_file)\n",
    "print(f\"扩展后的评论数据已保存: {enriched_file}\")\n",
    "\n",
    "# 保存过滤后的评论数据\n",
    "df_filtered = df_raw[df_raw['quality_score'] >= 5]\n",
    "filtered_file = PROCESSED_DATA_DIR / \"filtered_comments.csv\"\n",
    "df_filtered.to_csv(filtered_file)\n",
    "print(f\"过滤后的评论数据已保存: {filtered_file}\")\n",
    "\n",
    "# 数据展示\n",
    "df_filtered.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3：类别摘要生成\n",
    "\n",
    "为所需小类的评论生成关键词和摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 摘要生成 Prompt\n",
    "SUMMARIZATION_PROMPT = \"\"\"\n",
    "你是一位专业的内容摘要专家,请为以下类别的酒店评论生成一个摘要\n",
    "\n",
    "类别: {category}\n",
    "评论数量: {count}\n",
    "\n",
    "部分评论内容:\n",
    "{comments}\n",
    "\n",
    "请生成:\n",
    "1. 3-6个关键词（用逗号分隔）\n",
    "2. 一个300-500字的摘要,涵盖该类别的主要观点和代表性内容,不要出现酒店的具体名称\n",
    "3. 聚焦该类别下的话题，评论中出现的与该类别无关的内容请忽略\n",
    "\n",
    "直接返回JSON格式:\n",
    "{{\n",
    "    \"keywords\": \"关键词1,关键词2,关键词3,...\",\n",
    "    \"summary\": \"摘要内容\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def generate_summary(category: str, comments: list) -> dict:\n",
    "    \"\"\"为一个类别生成摘要\"\"\"\n",
    "    \n",
    "    # 选择高质量评论作为样本\n",
    "    sorted_comments = sorted(comments, key=lambda x: x['quality_score'], reverse=True)\n",
    "    sample_comments = \"\\n\".join([f\"- {c['comment'][:1000]}\" for c in sorted_comments[:500]])\n",
    "    \n",
    "    prompt = SUMMARIZATION_PROMPT.format(\n",
    "        category=category,\n",
    "        count=len(comments),\n",
    "        comments=sample_comments\n",
    "    )\n",
    "    \n",
    "    for i in range(3):\n",
    "        try:\n",
    "            response = llm_client.generate(prompt, temperature=0.5)\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            data = json.loads(response)\n",
    "            if data['keywords'] and data['summary']:\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            print(f\"类别 {category} 的摘要第 {i+1} 次尝试失败: {e}\")\n",
    "            if i < 2:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    \n",
    "    print(f\"类别 {category} 摘要生成失败，已返回空字符串\")\n",
    "    return {'keywords': \"\", 'summary': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ffeb489a30445d8aef04bbc830dcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "生成摘要:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成 14 个类别的摘要生成\n"
     ]
    }
   ],
   "source": [
    "# 批量生成摘要\n",
    "summaries = []\n",
    "\n",
    "for category, comments in tqdm(category_comments.items(), desc=\"生成摘要\"):\n",
    "    if category in my_categories:\n",
    "        result = generate_summary(category, comments)\n",
    "        summaries.append({\n",
    "            'category': category,\n",
    "            'keywords': result['keywords'],\n",
    "            'summary': result['summary'],\n",
    "            'comment_count': len(comments)\n",
    "        })\n",
    "        time.sleep(0.1)\n",
    "\n",
    "print(f\"已完成 {len([s for s in summaries if s['keywords']])} 个类别的摘要生成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摘要已保存: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\category_summaries.json\n"
     ]
    }
   ],
   "source": [
    "# 保存摘要\n",
    "summaries_file = PROCESSED_DATA_DIR / \"category_summaries.json\"\n",
    "with open(summaries_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summaries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"摘要已保存: {summaries_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4：反向 Query 生成\n",
    "\n",
    "为每条高质量评论生成 1-3 个关联问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向 Query 生成 Prompt\n",
    "REVERSE_QUERY_PROMPT = \"\"\"\n",
    "你是一位专业的问题生成专家,请基于以下酒店评论,生成1-3个用户可能会提出的问题,这些问题应该能被该评论很好地回答\n",
    "\n",
    "评论内容: {comment}\n",
    "\n",
    "要求:\n",
    "1. 问题要自然、口语化,符合用户提问习惯\n",
    "2. 问题要具体,能够被该评论直接回答\n",
    "3. 问题要涵盖评论的核心信息点\n",
    "4. 生成1-3个不同角度的问题\n",
    "5. 若评论本身包含的信息量很少,则生成1-2个问题即可,不用强行生成3个冗余或无效的问题,需保证问题与评论的相关性和问题的多样性\n",
    "6. 生成的问题中不要出现酒店的具体名称\n",
    "\n",
    "直接返回JSON格式:\n",
    "{{\n",
    "    \"queries\": [\"问题1\", \"问题2\", \"问题3\"]\n",
    "}}\n",
    "\n",
    "注意: queries数组中包含1-3个问题\n",
    "\"\"\"\n",
    "\n",
    "def generate_reverse_queries(comment: str, index: int) -> list:\n",
    "    \"\"\"为单条评论生成反向 Query\"\"\"\n",
    "    prompt = REVERSE_QUERY_PROMPT.format(comment=comment)\n",
    "    \n",
    "    for i in range(3):\n",
    "        try:\n",
    "            response = llm_client.generate(prompt, temperature=0.7)\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            data = json.loads(response)\n",
    "            queries = data['queries']\n",
    "            if isinstance(queries, list):\n",
    "                return queries\n",
    "            else:\n",
    "                raise TypeError(f\"queries 数据类型错误: 期望 list, 实际为 {type(queries).__name__}\")\n",
    "        except Exception as e:\n",
    "            print(f\"索引为 {index} 的评论第 {i+1} 次尝试失败: {e}\")\n",
    "            if i < 2:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    \n",
    "    print(f\"索引为 {index} 的评论生成反向 Query 失败，已返回空列表\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc98ba04d10b4f679dd0394ca58c9332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "生成反向Query:   0%|          | 0/2171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总 Query 数: 6441\n",
      "平均每条评论: 2.97 个 Query\n"
     ]
    }
   ],
   "source": [
    "# 批量生成反向 Query\n",
    "all_queries = []\n",
    "\n",
    "for index, row in tqdm(df_filtered.iterrows(), total=len(df_filtered), desc=\"生成反向Query\"):\n",
    "    queries = generate_reverse_queries(row['comment'], index)\n",
    "    \n",
    "    for query in queries:\n",
    "        all_queries.append({\n",
    "            'query': query,\n",
    "            'comment_id': index,\n",
    "            'comment': row['comment'],\n",
    "            'room_type': row['room_type'],\n",
    "            'fuzzy_room_type': row['fuzzy_room_type']\n",
    "        })\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "df_queries = pd.DataFrame(all_queries)\n",
    "\n",
    "print(f\"总 Query 数: {len(df_queries)}\")\n",
    "print(f\"平均每条评论: {len(df_queries) / len(df_filtered):.2f} 个 Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向 Query 数据已保存: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\reverse_queries.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>room_type</th>\n",
       "      <th>fuzzy_room_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>这家酒店的装修和设施怎么样？看照片有点担心，实际体验好吗？</td>\n",
       "      <td>68027895e3c98b0941765706</td>\n",
       "      <td>房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...</td>\n",
       "      <td>红棉大床套房</td>\n",
       "      <td>套房</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>这家酒店的服务具体好在哪些地方？和其他五星级酒店比如何？</td>\n",
       "      <td>68027895e3c98b0941765706</td>\n",
       "      <td>房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...</td>\n",
       "      <td>红棉大床套房</td>\n",
       "      <td>套房</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>酒店的自助餐和餐饮水平如何？有什么特色菜推荐吗？</td>\n",
       "      <td>68027895e3c98b0941765706</td>\n",
       "      <td>房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...</td>\n",
       "      <td>红棉大床套房</td>\n",
       "      <td>套房</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           query                comment_id  \\\n",
       "0  这家酒店的装修和设施怎么样？看照片有点担心，实际体验好吗？  68027895e3c98b0941765706   \n",
       "1   这家酒店的服务具体好在哪些地方？和其他五星级酒店比如何？  68027895e3c98b0941765706   \n",
       "2       酒店的自助餐和餐饮水平如何？有什么特色菜推荐吗？  68027895e3c98b0941765706   \n",
       "\n",
       "                                             comment room_type fuzzy_room_type  \n",
       "0  房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...    红棉大床套房              套房  \n",
       "1  房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...    红棉大床套房              套房  \n",
       "2  房间非常好 装修很厚重奢华 一开始看评论 看酒店自己po的照片 感觉跟快捷酒店一样 有些害怕...    红棉大床套房              套房  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存反向 Query 数据集\n",
    "queries_file = PROCESSED_DATA_DIR / \"reverse_queries.csv\"\n",
    "df_queries.to_csv(queries_file, index=False)\n",
    "\n",
    "print(f\"反向 Query 数据已保存: {queries_file}\")\n",
    "df_queries.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤5：向量数据库构建\n",
    "\n",
    "首先检查前四个步骤中 LLM 的指令遵循情况并手动调整不符合要求的数据\n",
    "\n",
    "确认数据无误后，构建三个向量数据库：\n",
    "\n",
    "1. **评论数据库** (DashVector) - 评论文本 embedding\n",
    "2. **反向 Query 数据库** (DashVector) - Query 文本 embedding\n",
    "3. **摘要数据库** (ChromaDB) - 类别关键词 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新加载数据\n",
    "filtered_file = PROCESSED_DATA_DIR / \"filtered_comments.csv\"\n",
    "queries_file = PROCESSED_DATA_DIR / \"reverse_queries.csv\"\n",
    "summaries_file = PROCESSED_DATA_DIR / \"category_summaries.json\"\n",
    "\n",
    "df_filtered = pd.read_csv(filtered_file, index_col=0)\n",
    "df_queries = pd.read_csv(queries_file)\n",
    "with open(summaries_file, 'r', encoding='utf-8') as f:\n",
    "    summaries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DashVector Collection 创建/获取函数\n",
    "def create_or_get_dashvector_collection(client, name: str, fields_schema: dict = None) -> any:\n",
    "    \"\"\"创建或获取 DashVector Collection\"\"\"\n",
    "    collection = client.get(name)\n",
    "    \n",
    "    if collection is not None:\n",
    "        stats = collection.stats()\n",
    "        code = stats.code if hasattr(stats, \"code\") else -1\n",
    "        \n",
    "        if code == 0:\n",
    "            print(f\"Collection '{name}' 已存在\")\n",
    "            return collection\n",
    "    \n",
    "    # 创建新 Collection\n",
    "    ret = client.create(\n",
    "        name=name,\n",
    "        dimension=EMBEDDING_DIMENSION,\n",
    "        metric=\"cosine\",\n",
    "        dtype=float,\n",
    "        fields_schema=fields_schema\n",
    "    )\n",
    "    \n",
    "    if ret and hasattr(ret, \"code\") and ret.code == 0:\n",
    "        print(f\"Collection '{name}' 创建成功\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"创建 Collection 失败: {ret}\")\n",
    "    \n",
    "    return client.get(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 构建评论数据库（DashVector）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'comment_database' 创建成功\n"
     ]
    }
   ],
   "source": [
    "# 创建评论 Collection\n",
    "comment_fields_schema = {\n",
    "    'comment': str,\n",
    "    'room_type': str,\n",
    "    'fuzzy_room_type': str\n",
    "}\n",
    "comment_collection = create_or_get_dashvector_collection(dashvector_client, \"comment_database\", comment_fields_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed8a24926ec4004bf0f64a5836d2bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "构建评论数据库:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数据库构建完成, 共更新 2171 条记录\n"
     ]
    }
   ],
   "source": [
    "# 生成评论 embedding 并插入\n",
    "comment_texts = df_filtered['comment'].tolist()\n",
    "total_inserted = 0\n",
    "\n",
    "for i in tqdm(range(0, len(comment_texts), BATCH_SIZE), desc=\"构建评论数据库\"):\n",
    "    batch_texts = comment_texts[i: i + BATCH_SIZE]\n",
    "    batch_embeddings = embedding_client.embed_batch(batch_texts)\n",
    "    \n",
    "    # 构建文档\n",
    "    docs = []\n",
    "    for j, embedding in enumerate(batch_embeddings):\n",
    "        idx = i + j\n",
    "        row = df_filtered.iloc[idx]\n",
    "        \n",
    "        docs.append(Doc(\n",
    "            id=row.name,\n",
    "            vector=embedding,\n",
    "            fields={\n",
    "                'comment': row['comment'],\n",
    "                'room_type': row['room_type'],\n",
    "                'fuzzy_room_type': row['fuzzy_room_type']\n",
    "            }\n",
    "        ))\n",
    "    \n",
    "    # 插入\n",
    "    response = comment_collection.upsert(docs)\n",
    "    if hasattr(response, \"code\") and response.code == 0:\n",
    "        total_inserted += len(docs)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"评论数据库构建完成, 共更新 {total_inserted} 条记录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 构建反向 Query 数据库（DashVector）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'reverse_query_database' 创建成功\n"
     ]
    }
   ],
   "source": [
    "# 创建反向 Query Collection\n",
    "query_fields_schema = {\n",
    "    'query': str,\n",
    "    'comment_id': str,\n",
    "    'comment': str,\n",
    "    'room_type': str,\n",
    "    'fuzzy_room_type': str\n",
    "}\n",
    "query_collection = create_or_get_dashvector_collection(dashvector_client, \"reverse_query_database\", query_fields_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce281b2b7db7483c81c2afec9c92b387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "构建反向Query数据库:   0%|          | 0/645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向 Query 数据库构建完成, 共更新 6441 条记录\n"
     ]
    }
   ],
   "source": [
    "# 生成 Query embedding 并插入\n",
    "query_texts = df_queries['query'].tolist()\n",
    "total_inserted = 0\n",
    "\n",
    "for i in tqdm(range(0, len(query_texts), BATCH_SIZE), desc=\"构建反向Query数据库\"):\n",
    "    batch_texts = query_texts[i: i + BATCH_SIZE]\n",
    "    batch_embeddings = embedding_client.embed_batch(batch_texts)\n",
    "    \n",
    "    docs = []\n",
    "    for j, embedding in enumerate(batch_embeddings):\n",
    "        idx = i + j\n",
    "        row = df_queries.iloc[idx]\n",
    "        \n",
    "        docs.append(Doc(\n",
    "            id=f'query_{idx}',\n",
    "            vector=embedding,\n",
    "            fields={\n",
    "                'query': row['query'],\n",
    "                'comment_id': row['comment_id'],\n",
    "                'comment': row['comment'],\n",
    "                'room_type': row['room_type'],\n",
    "                'fuzzy_room_type': row['fuzzy_room_type']\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    # 插入\n",
    "    response = query_collection.upsert(docs)\n",
    "    if hasattr(response, \"code\") and response.code == 0:\n",
    "        total_inserted += len(docs)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"反向 Query 数据库构建完成, 共更新 {total_inserted} 条记录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 构建摘要数据库（ChromaDB）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摘要数据库创建成功\n"
     ]
    }
   ],
   "source": [
    "# 删除旧数据库\n",
    "try:\n",
    "    chroma_client.delete_collection(\"summary_database\")\n",
    "    print(\"删除旧的摘要数据库\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 创建新数据库\n",
    "summary_collection = chroma_client.create_collection(\n",
    "    name=\"summary_database\",\n",
    "    metadata={'description': \"摘要数据库: 基于类别关键词的向量检索\", 'hnsw:space': \"cosine\"}  # 使用余弦相似度，若不指定，默认为 L2 欧氏距离\n",
    ")\n",
    "\n",
    "print(\"摘要数据库创建成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3c2e5660014b17863467b46412ed5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "构建摘要数据库:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摘要数据库构建完成, 共更新 14 条记录\n"
     ]
    }
   ],
   "source": [
    "# 生成关键词 Embedding 并插入\n",
    "keywords_list = [s['keywords'] for s in summaries]\n",
    "\n",
    "for i in tqdm(range(0, len(keywords_list), BATCH_SIZE), desc=\"构建摘要数据库\"):\n",
    "    batch_texts = keywords_list[i: i + BATCH_SIZE]\n",
    "    batch_embeddings = embedding_client.embed_batch(batch_texts)\n",
    "\n",
    "    num = len(batch_embeddings)\n",
    "    summary_collection.add(\n",
    "        ids=[f\"summary_{j}\" for j in range(i, i + num)],\n",
    "        embeddings=batch_embeddings,\n",
    "        documents=[s['summary'] for s in summaries[i: i + num]],\n",
    "        metadatas=[\n",
    "            {\n",
    "                'category': s['category'],\n",
    "                'keywords': s['keywords'],\n",
    "                'comment_count': s['comment_count']\n",
    "            }\n",
    "            for s in summaries[i: i + num]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(f\"摘要数据库构建完成, 共更新 {len(summaries)} 条记录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量数据库测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数据库查询测试:\n",
      "- 查询: 酒店博物馆如何？\n",
      "- 返回结果数: 3\n",
      "\n",
      "Top 1 结果:\n",
      "- 相似度: 0.3393\n",
      "- 评论: 酒店本身就是一个景点，最惊艳的是四楼的博物馆！\n",
      "- 房型: 花园双床房\n"
     ]
    }
   ],
   "source": [
    "# 验证评论数据库\n",
    "test_query = \"酒店博物馆如何？\"\n",
    "test_embedding = embedding_client.embed_batch([test_query])[0]\n",
    "\n",
    "results = comment_collection.query(vector=test_embedding, topk=3)\n",
    "\n",
    "print(\"评论数据库查询测试:\")\n",
    "print(f\"- 查询: {test_query}\")\n",
    "print(f\"- 返回结果数: {len(results)}\")\n",
    "\n",
    "print(f\"\\nTop 1 结果:\")\n",
    "print(f\"- 相似度: {results[0].score:.4f}\")\n",
    "print(f\"- 评论: {results[0].fields.get('comment', '')}\")\n",
    "print(f\"- 房型: {results[0].fields.get('room_type', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向 Query 数据库查询测试:\n",
      "- 查询: 酒店博物馆如何？\n",
      "- 返回结果数: 3\n",
      "\n",
      "Top 1 结果:\n",
      "- 相似度: 0.1171\n",
      "- Query: 酒店博物馆值得去看吗？对住客有没有什么特别待遇？\n",
      "- 关联评论: 老品牌，颇有底蕴的酒店。给人富丽贵气的感觉。喜欢酒店礼宾部Gary小陈的介绍。相比之下，四楼博物馆门口小哥的态度很让人费解，一个酒店博物馆不就是为了推介吸引参观吗，什么要预约扫码，还不对住客有专享，你以为自己专属文旅就可以这种态度对宾客？搞笑了，让人没胃口看了。\n",
      "- 模糊房型: 双床房\n"
     ]
    }
   ],
   "source": [
    "# 验证反向 Query 数据库\n",
    "results = query_collection.query(vector=test_embedding, topk=3)\n",
    "\n",
    "print(\"反向 Query 数据库查询测试:\")\n",
    "print(f\"- 查询: {test_query}\")\n",
    "print(f\"- 返回结果数: {len(results)}\")\n",
    "\n",
    "print(f\"\\nTop 1 结果:\")\n",
    "print(f\"- 相似度: {results[0].score:.4f}\")\n",
    "print(f\"- Query: {results[0].fields.get('query', '')}\")\n",
    "print(f\"- 关联评论: {results[0].fields.get('comment', '')}\")\n",
    "print(f\"- 模糊房型: {results[0].fields.get('fuzzy_room_type', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摘要数据库查询测试:\n",
      "- 查询: 酒店博物馆如何？\n",
      "- 返回结果数: 1\n",
      "\n",
      "Top 1 结果:\n",
      "- 类别: 公共设施\n",
      "- 关键词: 岭南园林花园,瀑布与锦鲤,酒店博物馆,金碧辉煌大堂,旋转楼梯与壁画,导览讲解服务\n",
      "- 摘要: 关于酒店的公共设施，评论普遍给予极高评价，认为其是酒店最核心的亮点与竞争力。主要观点集中在以下几个方面：\n",
      "\n",
      "首先，酒店内独具特色的岭南园林花园是几乎所有评论都提及的焦点。住客们惊叹于在市中心竟能拥有如此精致、静谧且打理用心的花园，其中人工双瀑布、小桥流水、池塘与成群锦鲤构成了核心景观，被誉为“城市绿洲”和“世外桃源”，特别适合亲子游玩、散步与拍照，完美诠释了酒店名称。\n",
      "\n",
      "其次，酒店内部充满艺术与文...\n"
     ]
    }
   ],
   "source": [
    "# 验证摘要数据库\n",
    "results = summary_collection.query(query_embeddings=[test_embedding], n_results=1)\n",
    "\n",
    "print(\"摘要数据库查询测试:\")\n",
    "print(f\"- 查询: {test_query}\")\n",
    "print(f\"- 返回结果数: {len(results['ids'][0])}\")\n",
    "\n",
    "# 获取 Top 1 结果\n",
    "metadata = results['metadatas'][0][0]\n",
    "document = results['documents'][0][0]\n",
    "\n",
    "print(f\"\\nTop 1 结果:\")\n",
    "print(f\"- 类别: {metadata.get('category', '')}\")\n",
    "print(f\"- 关键词: {metadata.get('keywords', '')}\")\n",
    "print(f\"- 摘要: {document[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤6：倒排索引构建\n",
    "\n",
    "基于 BM25 算法的传统关键词检索，支持精确匹配召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 倒排索引类定义\n",
    "class InvertedIndex:\n",
    "    \"\"\"基于 BM25 的倒排索引\"\"\"\n",
    "    \n",
    "    def __init__(self, k1: float = 1.5, b: float = 0.75, stopwords_file: str = None):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "            k1: BM25 参数，控制词频饱和度\n",
    "            b: BM25 参数，控制文档长度归一化程度\n",
    "        \"\"\"\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.index = {}          # {term: {doc_id: term_freq}}\n",
    "        self.doc_lengths = {}    # {doc_id: doc_length}\n",
    "        self.avg_doc_length = 0\n",
    "        self.num_docs = 0\n",
    "        self.documents = {}      # {doc_id: document_content}\n",
    "\n",
    "        # 加载停用词\n",
    "        self.stopwords = set()\n",
    "        if stopwords_file and Path(stopwords_file).exists():\n",
    "            with open(stopwords_file, encoding='utf-8') as f:\n",
    "                self.stopwords.update([line.strip() for line in f])\n",
    "            try:\n",
    "                self.stopwords.update(nltk.corpus.stopwords.words('english'))  # 加载英文停用词\n",
    "            except:\n",
    "                print(\"警告: 未能加载 NLTK 英文停用词\")\n",
    "        \n",
    "        # 字典预加载\n",
    "        jieba.initialize()\n",
    "    \n",
    "    def tokenize(self, text: str) -> list[str]:\n",
    "        \"\"\"分词与过滤\"\"\"     \n",
    "        \n",
    "        # 删除空白字符\n",
    "        text = re.sub(r'\\s+', '', text)\n",
    "        \n",
    "        # 中文分词\n",
    "        tokens = jieba.lcut(text)\n",
    "        \n",
    "        # 过滤停用词、非中英文字符，统一小写\n",
    "        pattern = re.compile(r'[^\\u4e00-\\u9fffa-zA-Z]')\n",
    "        tokens = [token.lower() for token in tokens if token.lower() not in self.stopwords and not pattern.search(token)]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def build(self, documents: dict[str, str]):\n",
    "        \"\"\"\n",
    "        构建倒排索引\n",
    "        \n",
    "        参数:\n",
    "            documents: {doc_id: document_text}\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.num_docs = len(documents)\n",
    "        \n",
    "        # 统计文档长度\n",
    "        total_length = 0\n",
    "        for doc_id, text in tqdm(documents.items(), desc=\"分词与统计\"):\n",
    "            tokens = self.tokenize(text)\n",
    "            doc_length = len(tokens)\n",
    "            self.doc_lengths[doc_id] = doc_length\n",
    "            total_length += doc_length\n",
    "            \n",
    "            # 构建倒排索引\n",
    "            term_freq = Counter(tokens)\n",
    "            for term, freq in term_freq.items():\n",
    "                if term not in self.index:\n",
    "                    self.index[term] = {}\n",
    "                self.index[term][doc_id] = freq\n",
    "        \n",
    "        self.avg_doc_length = total_length / self.num_docs if self.num_docs > 0 else 0\n",
    "        print(f\"倒排索引构建完成: {len(self.index)} 个词项, {self.num_docs} 篇文档\")\n",
    "        print(f\"平均文档长度: {self.avg_doc_length:.2f} 个词\")\n",
    "    \n",
    "    def search(self, query: str, topk: int = 10) -> list[tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        BM25 检索\n",
    "        \n",
    "        参数:\n",
    "            query: 查询文本\n",
    "            topk: 返回 Top-K 结果\n",
    "        \n",
    "        返回:\n",
    "            [(doc_id, bm25_score), ...]\n",
    "        \"\"\"\n",
    "        query_tokens = self.tokenize(query)\n",
    "\n",
    "        if not query_tokens:\n",
    "            return []\n",
    "        \n",
    "        # 计算 IDF\n",
    "        idf = {}\n",
    "        for term in query_tokens:\n",
    "            if term in self.index:\n",
    "                df = len(self.index[term])  # 文档频率\n",
    "                idf[term] = max(0, (self.num_docs - df + 0.5) / (df + 0.5) + 1)\n",
    "        \n",
    "        # 计算 BM25 分数\n",
    "        scores = {}\n",
    "        for term in query_tokens:\n",
    "            if term not in self.index:\n",
    "                continue\n",
    "            \n",
    "            for doc_id, tf in self.index[term].items():\n",
    "                if doc_id not in scores:\n",
    "                    scores[doc_id] = 0\n",
    "                \n",
    "                doc_length = self.doc_lengths[doc_id]\n",
    "                norm_factor = 1 - self.b + self.b * (doc_length / self.avg_doc_length)\n",
    "                term_score = idf[term] * (tf * (self.k1 + 1)) / (tf + self.k1 * norm_factor)\n",
    "                scores[doc_id] = scores.get(doc_id, 0) + term_score\n",
    "        \n",
    "        # 排序并返回 Top-K\n",
    "        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "        return sorted_docs\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"保存索引到文件\"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'index': self.index,\n",
    "                'doc_lengths': self.doc_lengths,\n",
    "                'avg_doc_length': self.avg_doc_length,\n",
    "                'num_docs': self.num_docs,\n",
    "                'documents': self.documents,\n",
    "                'k1': self.k1,\n",
    "                'b': self.b,\n",
    "                'stopwords': self.stopwords\n",
    "            }, f)\n",
    "        print(f\"倒排索引已保存: {filepath}\")\n",
    "    \n",
    "    def load(self, filepath: str):\n",
    "        \"\"\"从文件加载索引\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.index = data['index']\n",
    "            self.doc_lengths = data['doc_lengths']\n",
    "            self.avg_doc_length = data['avg_doc_length']\n",
    "            self.num_docs = data['num_docs']\n",
    "            self.documents = data['documents']\n",
    "            self.k1 = data['k1']\n",
    "            self.b = data['b']\n",
    "            self.stopwords = data.get('stopwords', set())\n",
    "        print(f\"倒排索引已加载\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\22418\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.605 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0554dc66e64dc9bc825c187ea7471e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "分词与统计:   0%|          | 0/2171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "倒排索引构建完成: 10734 个词项, 2171 篇文档\n",
      "平均文档长度: 41.62 个词\n",
      "倒排索引已保存: C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\inverted_index.pkl\n"
     ]
    }
   ],
   "source": [
    "# 构建倒排索引\n",
    "stopwords_file = CONFIG_DIR / \"stopwords_chinese.txt\"                          # 中文停用词文件路径\n",
    "inverted_index = InvertedIndex(k1=1.5, b=0.75, stopwords_file=stopwords_file)\n",
    "documents = {idx: row['comment'] for idx, row in df_filtered.iterrows()}       # 使用 comment_id 作为 doc_id\n",
    "inverted_index.build(documents)\n",
    "\n",
    "# 保存倒排索引\n",
    "index_file = PROCESSED_DATA_DIR / \"inverted_index.pkl\"\n",
    "inverted_index.save(index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 倒排索引测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "倒排索引已加载\n",
      "\n",
      "倒排索引查询测试:\n",
      "- 原始查询: 酒店博物馆和瀑布花园如何？\n",
      "- 分词结果: ['酒店', '博物馆', '瀑布', '花园']\n",
      "- 返回结果数: 3\n",
      "\n",
      "Top 1 结果:\n",
      "- BM25 分数: 26.2280\n",
      "- 评论: 酒店就是住在花园里，亮点是花园瀑布下午茶，还有4楼博物馆也可免费参观，很不错的体验哦\n"
     ]
    }
   ],
   "source": [
    "# 加载倒排索引\n",
    "inverted_index = InvertedIndex()\n",
    "inverted_index.load(index_file)\n",
    "\n",
    "# 验证倒排索引\n",
    "test_query_bm25 = \"酒店博物馆和瀑布花园如何？\"\n",
    "bm25_results = inverted_index.search(test_query_bm25, topk=3)\n",
    "\n",
    "print(\"\\n倒排索引查询测试:\")\n",
    "print(f\"- 原始查询: {test_query_bm25}\")\n",
    "print(f\"- 分词结果: {inverted_index.tokenize(test_query_bm25)}\")\n",
    "print(f\"- 返回结果数: {len(bm25_results)}\")\n",
    "\n",
    "# 获取 Top 1 结果\n",
    "doc_id, score = bm25_results[0]\n",
    "comment = df_filtered.loc[doc_id]\n",
    "\n",
    "print(f\"\\nTop 1 结果:\")\n",
    "print(f\"- BM25 分数: {score:.4f}\")\n",
    "print(f\"- 评论: {comment['comment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "第一模块（离线知识库构建）已全部完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据过滤:\n",
      "- 原数据评论数: 2542\n",
      "- 过滤后评论数: 2171 (quality_score >= 5)\n",
      "\n",
      "向量数据库:\n",
      "1. 评论数据库 (DashVector): 2171 条\n",
      "2. 反向 Query 数据库 (DashVector): 6441 条\n",
      "3. 摘要数据库 (ChromaDB): 14 条\n",
      "\n",
      "倒排索引:\n",
      "4. BM25 倒排索引: 10734 个词项, 2171 条评论\n",
      "\n",
      "输出文件:\n",
      "- C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\enriched_comments.csv\n",
      "- C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\filtered_comments.csv\n",
      "- C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\reverse_queries.csv\n",
      "- C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\category_summaries.json\n",
      "- C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\chroma_db\\ (ChromaDB)\n",
      "- C:\\Users\\22418\\Desktop\\Scorpio\\复旦\\课程\\大三下\\酒店评论\\data\\processed\\inverted_index.pkl\n"
     ]
    }
   ],
   "source": [
    "print(f\"数据过滤:\")\n",
    "print(f\"- 原数据评论数: {len(df_raw)}\")\n",
    "print(f\"- 过滤后评论数: {len(df_filtered)} (quality_score >= 5)\")\n",
    "\n",
    "print(f\"\\n向量数据库:\")\n",
    "print(f\"1. 评论数据库 (DashVector): {len(df_filtered)} 条\")\n",
    "print(f\"2. 反向 Query 数据库 (DashVector): {len(df_queries)} 条\")\n",
    "print(f\"3. 摘要数据库 (ChromaDB): {len(summaries)} 条\")\n",
    "\n",
    "print(f\"\\n倒排索引:\")\n",
    "print(f\"4. BM25 倒排索引: {len(inverted_index.index)} 个词项, {inverted_index.num_docs} 条评论\")\n",
    "\n",
    "print(f\"\\n输出文件:\")\n",
    "print(f\"- {enriched_file}\")\n",
    "print(f\"- {filtered_file}\")\n",
    "print(f\"- {queries_file}\")\n",
    "print(f\"- {summaries_file}\")\n",
    "print(f\"- {chroma_db_path}\\\\ (ChromaDB)\")\n",
    "print(f\"- {index_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
