# 酒店评论RAG系统

## 1. 项目概述

### 1.1 项目背景

在酒旅行业，在线用户评论是反映客户体验、服务质量及潜在需求的核心数据资产。广州花园酒店在2023-2025年间积累了2542条线上评论数据，然而传统的客服系统难以有效利用这些非结构化文本来回答用户复杂、模糊的咨询，导致服务体验存在断层。

### 1.2 项目目标

本项目旨在构建一个垂直领域RAG智能客服系统。该系统不依赖于传统的FAQ库，而是深度理解和利用真实用户评论数据，通过多维度的知识构建、复杂的意图理解和混合检索策略，为用户提供精准、真实、具有参考价值的住宿建议和即时问答服务，从而提升客户体验。

### 1.3 核心技术路线

项目基于Python生态构建，核心能力由Qwen/DeepSeek大模型系列提供支撑，数据存储与检索依赖高性能向量数据库 (DashVector + ChromaDB) 及倒排索引技术。系统架构采用了 **"离线知识结构化 + 在线多路召回 + 多因子重排 + 回复生成"** 的RAG范式。

---

## 2. 总体架构

本系统采用经典的RAG架构设计，强调数据流动的清晰性和各模块的解耦。整体流程从原始数据到最终用户回答分为离线和在线两大阶段:

```
离线阶段: 原始评论 → 质量评估 → 分类 → 摘要生成 → 反向 Query 生成 → 多维索引构建
在线阶段: 用户 Query → 查询处理 → 五路混合检索 → 多因子重排 → 回复生成
```

---

## 3. 模块设计

本系统共包含五个核心功能模块，每个模块都针对非结构化评论数据的特性进行了深度定制。

### 3.1 模块一: 离线知识库构建

此模块是整个系统的基石，负责将杂乱的原始评论转化为高信噪比、多维度的可检索知识库。

#### 3.1.1 评论质量评估

**输入**: 原始CSV文件 (包含评论文本、评分、发布日期、房型、点赞数、回复数等)。

**处理流程**:
1. 调用LLM (DeepSeek-v3.2) 对每一条评论进行质量打分 (0-10分制)
2. 评估维度包括:
   - 信息量充分性
   - 具体性和细节丰富度
   - 对酒店设施/服务的描述完整性
   - 对其他用户的参考价值

**过滤策略**: 
- 设定质量阈值 (quality_score >= 5)
- 过滤掉低质量评论 (如仅包含"好"、"不错"等短语)
- 原始2542条评论过滤后保留2171条高质量评论

**输出**: 
- `enriched_comments.csv`: 包含质量评分的完整评论数据
- `filtered_comments.csv`: 过滤后的高质量评论数据

#### 3.1.2 多级原型映射

利用LLM强大的理解能力，将每条评论划分至以下二级分类体系中的1-3个主要小类:

```
├── 设施类
│   ├── 房间设施
│   ├── 公共设施
│   └── 餐饮设施
├── 服务类
│   ├── 前台服务
│   ├── 客房服务
│   └── 退房/入住效率
├── 位置类
│   ├── 交通便利性
│   ├── 周边配套
│   └── 景观/朝向
├── 价格类
│   ├── 性价比
│   └── 价格合理性
└── 体验类
    ├── 整体满意度
    ├── 安静程度
    └── 卫生状况
```

#### 3.1.3 类别摘要生成

针对每个二级小类，聚合该类别下的评论文本，使用LLM生成相应的的评论摘要。

**相关要求**: 
- 摘要控制在300-500字
- 同时记录该类别的评论数量和关键词

**输出**: 
- `category_summaries.json`: 包含14个类别的摘要信息
- 每个摘要包含: category (类别名)、keywords (关键词)、summary (摘要文本)、comment_count (评论数量)

#### 3.1.4 反向Query生成

利用LLM对每一条原始评论进行深度分析，生成1-3条用户可能会提出的、且该评论能完美回答的潜在问题。

**目的**: 
- 解决检索时 Query (疑问句) 与 Comment (陈述句) 句式不匹配的问题
- 实现"以问找答"的反向召回机制

**实现细节**:
- 每条评论生成1-3个潜在问题
- 问题采用用户常见的口语化表达
- 2171条评论共生成6441条反向Query

**输出**: 
- `reverse_queries.csv`: 包含comment_id和对应的generated_queries列表

#### 3.1.5 多维索引与数据库构建

为支持复杂的检索需求，本系统构建了 **"三向量库+一倒排索引"** 的复合存储结构:

##### 1. 评论数据库 (DashVector)

- **内容**: 存储原始评论文本
- **索引**: 使用text-embedding-v4模型对**评论文本**进行编码 (1024维)
- **元数据**: 房型与模糊房型
- **用途**: 基于语义相似度直接检索评论
- **规模**: 2171条评论

##### 2. 反向Query数据库 (DashVector)

- **内容**: 存储原始评论文本与反向Query文本
- **索引**: 使用text-embedding-v4模型对**生成的反向Query**进行编码 (1024维)
- **元数据**: 房型与模糊房型
- **用途**: 通过"问题对问题"的匹配方式，精准定位能回答用户提问的评论
- **规模**: 6441条Query向量 (对应2171条评论)

##### 3. 摘要数据库 (ChromaDB)

- **内容**: 存储各二级小类的类别摘要文本
- **索引**: 使用text-embedding-v4模型对**类别关键词**进行编码 (1024维)
  - **注意**: 不是对摘要文本编码，而是对类别关键词编码
  - **例如**: "餐饮设施"的关键词是 ["米其林餐厅, 行政酒廊, 自助早餐, 广式茶点, 服务专业, 环境优雅"]
- **元数据**: 包含category (类别名)、keywords (关键词)、comment_count (评论数)
- **用途**: 通过Query与类别维度的匹配，快速召回宏观层面的总结信息
- **规模**: 14条类别摘要

##### 4. 倒排索引 (BM25)

- **内容**: 对评论文本进行分词处理，构建词项到文档的映射
- **算法**: BM25算法 (k1=1.5, b=0.75)
- **分词工具**: jieba中文分词
- **停用词**: 加载中文停用词表 + NLTK英文停用词
- **用途**: 支持基于关键词精确匹配的召回，特别适合包含特定实体词的查询
- **规模**: 10734个词项，索引2171条评论

**输出**: 
- `inverted_index.pkl`: 序列化的倒排索引文件

---

### 3.2 模块二: 查询处理

此模块作为在线系统的入口，负责精准捕捉和理解用户的真实意图。

#### 3.2.1 意图识别

使用LLM判断用户Query是否需要检索知识库，还是可以直接回答。

**判断标准**:
- **需要检索**: 询问酒店具体信息、设施、服务、位置等
- **直接回答**: 简单问候、闲聊、通用知识、无关问题等

**输出**: `need_retrieval` 字段，标记是否需要检索

#### 3.2.2 意图检测

在意图识别后，提取可能影响决策的关键约束信息:

1. **特定房型关注**
   - 精确房型: 15种具体房型 (如"花园大床房"、"红棉双床套房")
   - 模糊房型: 4种大类 (大床房、双床房、套房、主题房)
   - 用途: 作为约束条件在召回阶段过滤结果

2. **时效性需求**
   - 识别时间相关词汇: "最近"、"今年"、"最新"、"还"、"仍然"等
   - 包含: "clear" (明确时效性需求)、"implied" (隐含时效性需求) 、None (无时效性需求) 三级
   - 用途: 在重排阶段增大时效性衰减率

**输出**: 
- `room_type`, `fuzzy_room_type`: 两种房型约束
- `time_sensitivity`: 存在何种时效性需求

#### 3.2.3 意图扩展

使用LLM将原始Query扩展为1-3个更具体的子意图，并为每个子意图分配权重。

**扩展策略**:
- 分析用户Query的多个可能含义
- 为每个子意图生成更清晰的Query表述
- 分配权重总和为1.0

**示例**:
```
原始Query: "该酒店是否便捷?"

扩展结果:
1. "酒店交通是否便利，周边有哪些公共交通设施?" (权重: 0.6)
2. "酒店周边商业设施是否丰富?" (权重: 0.2)
3. "酒店办理入住和退房是否快速高效?" (权重: 0.2)
```

**输出**: `intent_expansion` 列表，包含扩展后的Query和对应权重

#### 3.2.4 HyDE假设性回复生成

利用HyDE技术解决检索时的语义鸿沟。根据扩展后的每条Query，使用LLM生成**3条假设性回复**。

**HyDE原理**:
- 利用生成的"理想答案"去寻找相应的真实评论
- 通过假设性回复的Embedding与评论库匹配，实现句式匹配并扩大搜索范围

**生成策略**:
- 为每个扩展Query生成3条假设性评论
- 两条偏正面，一条偏负面
- 保持检索结果的全面性和平衡性

**示例**:
```
Query: "酒店交通是否便利?"

假设回复1 (正面): "这家酒店交通非常便利，出门就是地铁站，步行3分钟就能到，去机场也很方便，有直达大巴，周边公交线路很多，打车也方便，位置真的很好找。"

假设回复2 (正面): "酒店地理位置优越，离地铁口特别近，周边交通四通八达，无论是去市区景点还是机场高铁站都很方便，门口就有共享单车，出行非常便捷。"

假设回复3 (负面): "酒店位置比较偏僻，离地铁站有一定距离，步行要20分钟左右，打车也不太好叫，周边公交线路较少，出行不是很方便，需要提前规划好交通。"
```

**输出**: 每个扩展Query对应3条假设回复，用于后续HyDE召回

---

### 3.3 模块三: 混合检索

为解决单一检索方式的局限性，本项目设计了五路并行召回机制，旨在最大化相关信息的覆盖率。

#### 3.3.1 第一路: BM25文本召回

**数据源**: 倒排索引 (基于jieba分词的BM25算法)

**召回流程**:
1. 对扩展后的每个Query进行分词
2. 在倒排索引中进行BM25检索
3. 每个Query返回Top-150结果

**适用场景**: 包含特定实体词 (如地名、设施名) 的查询

#### 3.3.2 第二路: 基础向量召回

**数据源**: 评论数据库 (DashVector)

**召回流程**:
1. 对扩展后的每个Query进行Embedding
2. 在评论向量库中进行ANN (近似最近邻) 检索
3. 如有房型约束，添加filter参数过滤
4. 每个Query返回Top-150结果

#### 3.3.3 第三路: 反向Query召回

**数据源**: 反向Query数据库 (DashVector)

**召回流程**:
1. 对扩展后的每个Query进行Embedding
2. 在反向Query向量库中进行ANN检索
3. 如有房型约束，添加filter参数过滤
4. 返回Query向量与生成Query向量最匹配的评论
5. 每个Query返回Top-150结果

**核心目的**: 
- 解决 Query (疑问句) 与 Comment (陈述句) 句式差异导致的向量空间距离过大的问题
- 实现"以问找答"的匹配机制

#### 3.3.4 第四路: HyDE增强召回

**数据源**: 评论数据库 (DashVector)

**召回流程**:
1. 对查询处理阶段生成的假设性回复进行Embedding
2. 在评论向量库中进行ANN检索
3. 如有房型约束，添加filter参数过滤
4. 每个假设回复返回Top-150结果

**核心目的**:
- 利用生成的"理想答案"去寻找相应的真实评论
- 通过引入正负两面的假设来平衡检索结果

**去重策略**:
- **问题**: 同一个Query的多条HyDE假设回复可能召回相同的评论，使得HyDE通道权重过高
- **方案**: 对于同一条评论，在同一个Query下只保留排名最靠前的那次召回

#### 3.3.5 第五路: 类别摘要召回 (单独路径)

**数据源**: 摘要数据库 (ChromaDB)

**召回流程**:
1. 对扩展后的每个Query进行Embedding
2. 在摘要类别关键词向量库中进行检索
3. 每个Query召回Top-1最相关类别对应的摘要文本并去重

**用途**: 
- 提供类别层面的总结信息
- 补充详细评论的整体背景

#### 3.3.6 RRF融合

完成五路召回后 (BM25、向量、反向、HyDE、摘要)，使用 **加权 RRF (Weighted Reciprocal Rank Fusion)** 算法对前四路召回的评论进行统一的去重和过滤。

**加权RRF公式**:
```
score(d) = Σ weight(q) × 1/(k + rank(d,q,i))
```
其中:
- k = 60 (平滑参数)
- rank(d,q,i) 是文档d在第q个Query的第i条召回通路中的排名
- weight(q) 是第q个Query的意图权重 (来自意图扩展阶段)

**融合流程**:
1. 收集前四路召回的所有结果
2. 对每个文档计算加权RRF分数
3. 按加权RRF分数降序排序
4. 保留Top-100进入下一阶段

**输出**: 
- 融合后的Top-100评论列表
- 各路召回的命中路由信息

---

### 3.4 模块四: 重排

对召回阶段的粗选结果 (Top-100) 进行多因子排序，最终选出Top-10最优评论。

#### 3.4.1 Rerank相关性打分

**模型**: Qwen3-Rerank

**处理流程**:
1. 将原始Query和每条召回评论组成Query-Comment对
2. 调用Rerank API批量计算相关性分数
3. 返回每条评论的relevance_score (0-1之间)

#### 3.4.2 多维特征计算

为每条评论计算以下特征维度:

| 特征维度 | 计算方式 | 取值范围 | 说明 |
|---------|---------|---------|------|
| **相关性** | Rerank模型输出 | 0-1 | 衡量评论与Query的匹配程度 |
| **评论质量分** | 离线质量评分归一化 | 0-1 | quality_score / 10 |
| **评论长度** | log(len(comment) + 1) 归一化 | 0-1 | 信息量指标 |
| **回复数** | log(review_count + 1) 归一化 | 0-1 | 受关注度 |
| **点赞数** | log(useful_count + 1) 归一化 | 0-1 | 用户认可度 |
| **时效性** | 时间衰减函数 | 0-1 | 越近期分数越高 |

注：内容质量包含评论质量分、评论长度、回复数、点赞数四个特征

**时效性计算**:

时效性使用指数衰减函数，并根据用户的时效性需求动态调整衰减率: `Exp(-decay × days / half_life)`

**参数配置**:
- `base_decay`: 基础衰减率 = 0.5
- `implied_boost`: implied级别额外增量 = 0.5
- `clear_boost`: clear级别额外增量 = 0.5
- `half_life_days`: 半衰期 = 180天

**三级时效性需求**:

| 级别 | 触发条件 | 衰减率 | 说明 |
|-----|---------|--------|------|
| **none** | 无时间相关词汇 | 0.5 | 温和衰减，近期评论略有优势 |
| **implied** | 隐含时间需求 (如"还"、"仍然") | 1.0 | 中等衰减，近期评论有明显优势 |
| **clear** | 明确时间需求 (如"最近"、"今年"、"最新") | 1.5 | 快速衰减，近期评论有很大优势 |

#### 3.4.3 线性加权融合

使用线性模型融合各维度特征:

```
final_score = 0.40 * relevance_score  (相关性)
            + 0.25 * norm_quality     (评论质量分)
            + 0.05 * norm_length      (评论长度)
            + 0.05 * norm_review      (回复数)
            + 0.05 * norm_useful      (点赞数)
            + 0.20 * recency_score    (时效性)
```

#### 3.4.4 最终排序

1. 为每条评论计算final_score
2. 按final_score降序排序
3. 截取Top-10作为最终的检索上下文

**输出**: Top-10高质量评论，包含:
- 评论内容和元数据
- RRF分数和排名
- Rerank分数和排名
- 最终综合分数和排名
- 各维度特征分数
- 召回路由信息

---

### 3.5 模块五: 回复生成

最后阶段，LLM充当"生成器"角色，基于检索到的上下文生成最终回复。

#### 3.5.1 上下文构建

**输入内容**:
1. **用户原始Query**: 确保回答问题的准确性
2. **意图扩展结果**: 展示理解的多个子意图
3. **Top-10评论**: 核心参考依据
4. **类别摘要**: 提供总体印象

#### 3.5.2 提示词工程：
- 客观性：需同时涵盖正面与负面评价，避免以偏概全
- 引用规范：合并相似观点，引用时需明确指出引用评论序号
- 时效性响应：仅在用户意图敏感时强调时间信息
- 摘要使用：利用摘要提供模糊概览，补充宏观视角

#### 3.5.3 流式输出
- 使用流式API生成回复，提供更好的用户体验
- 便于计算首字延迟

#### 3.5.4 延迟指标

系统跟踪以下关键延迟指标:

- **TTFT (Time To First Token)**: 首字延迟，从发送提问到收到第一个 token
- **Total Time**: 端到端总延迟

**延迟构成**:
```
TTFT  = Query Processing + Retrieval + Ranking + Model TTFT
Total = Query Processing + Retrieval + Ranking + Generation
```

**输出**: 
- 流式生成的回复文本
- 详细的延迟统计信息
- 完整的检索和排序过程信息

---

## 4. 技术栈

### 4.1 核心依赖

| 类别 | 技术/库 | 用途 |
|------|--------|------|
| **大模型API** | DashScope | 调用Qwen/DeepSeek模型 |
| **向量数据库** | DashVector | 云端向量检索服务 |
| **向量数据库** | ChromaDB | 本地向量数据库 |
| **分词** | jieba | 中文分词 |
| **停用词** | NLTK | 英文停用词 |
| **数据处理** | pandas | 表格数据处理 |
| **数值计算** | numpy | 向量和数值运算 |

### 4.2 模型配置

| 模型类型 | 模型名称 | 用途 |
|---------|---------|------|
| **LLM** | deepseek-v3.2 | 质量评估、分类、摘要、反向Query生成、回复生成 |
| **LLM** | qwen-plus | 意图检测 |
| **LLM** | qwen-flash | 意图扩展、HyDE生成 |
| **Embedding** | text-embedding-v4 | 文本向量化 |
| **Recognition** | tongyi-intent-detect-v3 | 意图识别 |
| **Rerank** | qwen3-rerank | 相关性打分 |

### 4.3 数据库配置

| 数据库 | 类型 | 容量 | 向量维度 | 用途 |
|--------|------|------|---------|------|
| **comment_database** | DashVector | 2171条 | 1024 | 评论向量检索 |
| **reverse_query_database** | DashVector | 6441条 | 1024 | 反向Query检索 |
| **summary_database** | ChromaDB | 14条 | 1024 | 类别摘要检索 |
| **inverted_index.pkl** | Pickle文件 | 10734词项 | - | BM25文本检索 |

---

## 5. 数据流转

### 5.1 离线数据流

```
原始评论 (2542条)
    ↓ [质量评估]
高质量评论 (2171条, quality_score >= 5)
    ↓ [多级分类]
分类评论 (2171条, 每条1-3个类别)
    ↓ [类别聚合]
类别摘要 (14个小类)
    ↓ [反向Query生成]
反向Query (6441条, 平均每条评论3个)
    ↓ [向量化]
三个向量库 + 一个倒排索引
```

### 5.2 在线数据流

```
用户Query
    ↓ [意图识别] (是否需要检索?)
    ├─ 不需要 → [直接回答]
    └─ 需要
        ↓
        ↓ [意图处理并行]
        ├─ [意图检测] (提取房型、时效性约束)
        └─ [意图扩展] (1-3个子Query + 权重)
        ↓
        ↓ [五路召回并行]
        ├─ BM25召回 (倒排索引)
        ├─ 向量召回 (评论向量库)
        ├─ 反向召回 (反向Query库)
        ├─ HyDE召回
        |   ├─ [HyDE生成] (每个子Query生成3条假设回复)
        |   └─ [HyDE检索] (评论向量库)
        └─ 摘要召回 (类别摘要库，单独路径)
        ↓
        ↓ [RRF融合] (Top-100)
        ↓ 
        ↓ [Rerank] (相关性打分)
        ↓ [多因子重排] (相关性、内容质量、时效性, Top-10)
        ↓
        ↓ [上下文组装]
        ↓ [流式生成]
        ↓
最终回复 + 检索详情
```

---

## 6. 关键特性

### 6.1 多路召回策略

- **五路互补**: BM25 (关键词) + 向量 (语义) + 反向 (问答) + HyDE (假设) + 摘要 (总体)
- **路由追踪**: 记录每条评论/摘要被哪些路由、哪个Query、在第几名召回
- **RRF融合**: 平衡不同召回源的贡献，避免某一路占主导

### 6.2 反向召回机制

- **以问找答**: 通过"问题对问题"匹配，精准定位能回答的评论
- **规模扩大**: 从2171条评论扩展到6441条反向Query向量
- **句式对齐**: 统一Query和索引内容的句式风格

### 6.3 HyDE技术

- **语义鸿沟**: 解决 Query (疑问句) 与 Comment (陈述句) 的匹配问题
- **正负平衡**: 生成正面和负面假设，确保检索结果的全面性
- **扩大范围**: 多条假设回复大幅增大能够匹配到的语义空间

### 6.4 房型约束过滤

- **精确匹配**: 15种具体房型 (如"花园大床房")
- **模糊匹配**: 4种大类 (大床房、双床房、套房、主题房)
- **动态过滤**: 在向量召回时实时添加filter参数

### 6.5 时效性动态调整

- **指数衰减**: 使用半衰期模型 (默认180天) 计算时间分数
- **需求检测**: 自动识别"最近"、"今年"等时间词汇，分为"clear"、"implied"、None三级
- **权重调整**: 根据用户的时效性需求逐级增大衰减率

### 6.6 完整的可观测性

- **延迟追踪**: 记录每个模块的耗时(查询处理、检索、排序、生成)
- **召回详情**: 展示每条评论的召回路由、Query索引、排名信息
- **特征透明**: 显示排序阶段的各维度特征分数和计算公式
- **中间结果**: 展示意图识别、检测、扩展结果和生成的假设性回复内容

---

## 7. 总结

本项目构建了一个完整的酒店评论RAG系统，具有以下核心特点:

1. **多维知识构建**: 质量评估 + 多级分类 + 类别摘要 + 反向Query + 倒排索引
2. **五路混合召回**: BM25 + 向量 + 反向 + HyDE + 摘要，最大化召回覆盖率
3. **多因子重排**: 相关性 (Rerank) + 内容质量 (评论质量分 + 评论长度 + 回复数 + 点赞数) + 时效性 (动态衰减率调整)
4. **约束条件支持**: 房型约束 + 时效性需求
5. **完整可观测性**: 延迟追踪 + 召回详情 + 特征透明

该系统通过深度理解真实用户评论，为酒店客户提供精准、客观、有参考价值的住宿建议，有效提升了客户服务体验。
